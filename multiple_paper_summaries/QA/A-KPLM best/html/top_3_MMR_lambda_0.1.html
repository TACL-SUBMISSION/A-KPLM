<html>
<head><title>sentence_pooling_strategy_top_3_adaptive_kplm_diversification_strategy_mmr_MMR_scoring_core_multinomial_cosine_MMR_alpha_0.1_dirichlet_prior_1_vectorisation_strategy_CountVectorizer_first_sent_selection_strategy_centroid_250_trimmed</title></head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>TARGETANCHOR focused on decomposition of a complex question into several sub-questions. </a>
<a name="2">[2]</a> <a href="#2" id=2>In addition, a number of researchers have built systems to take reading comprehension examinations designed to evaluate children's reading levels (Charniak et al, 2000; Hirschman et al, 1999; Ng et al, 2000; Riloff and Thelen, 2000; TARGETANCHOR). </a>
<a name="3">[3]</a> <a href="#3" id=3>The so-called "definition" or "other" questions at recent TREC evaluations TARGETANCHOR serve as good examples: "good answers" to these questions include interesting "nuggets" about a particular person, organization, entity, or event. </a>
<a name="4">[4]</a> <a href="#4" id=4>Further improvements may be possible by using a sentence splitter instead of windows of fixed length, anaphora resolution, clustering of similar snippets to avoid ranking them separately, and identifying additional n-gram attributes by bootstrapping TARGETANCHOR. </a>
<a name="5">[5]</a> <a href="#5" id=5>Also, as pointed out by TARGETANCHOR, a score distribution heavily skewed towards zero makes meta-analysis of evaluation stability hard to perform. </a>
<a name="6">[6]</a> <a href="#6" id=6>For example, TARGETANCHOR, Miller, Herschman, and Kelly (1978) on the LADDER system, and Biermann, Ballard, and Sigmon (1983) reported software failures at the rates of approximately 5, 2, and 2 percents, respectively. </a>
<a name="7">[7]</a> <a href="#7" id=7>Moreover, the proof relies on lexico-semantic knowledge available from WordNet as well as rapidly formated knowledge bases generated by mechanisms described in TARGETANCHOR. </a>
<a name="8">[8]</a> <a href="#8" id=8>Automatic pattern derivation is more appealing TARGETANCHOR. </a>
<a name="9">[9]</a> <a href="#9" id=9>Quarc TARGETANCHOR utilizes manually generated rules that selects a sentence deemed to contain the answer based on a combination of syntactic similarity and semantic correspondence (i.e., semantic categories of nouns). </a>
<a name="10">[10]</a> <a href="#10" id=10>Current systems TARGETANCHOR already employ traditional information extraction and machine learning for extracting answers from relevant documents. </a>
<a name="11">[11]</a> <a href="#11" id=11>TARGETANCHOR summarizes experience with the Transformational </a>
</body>
</html>