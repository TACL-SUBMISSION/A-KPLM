TARGETANCHOR focused on decomposition of a complex question into several sub-questions.
There are many previous work on paraphrase examples extraction or combining them with some applications such as information retrieval and question answering (Agichtein et al, 2001; Florence et al, 2003; TARGETANCHOR; Tomuro, 2003; Lin and Pantel, 2001;), information extraction (Shinyama et al, 2002; Shinyama and Sekine, 2003), machine translation (Hiroshi et al, 2003; Zhang and Yamamoto, 2003), multi-document (Barzilay et al, 2003).
QA is different than search engines in two aspects: (i) instead of a string of keyword search terms, the query is a natural language question, necessitating question parsing, (ii) instead of a list of documents or URLs, a list of candidate answers at phrase level or sentence level are expected to be returned in response to a query, hence the need for text processing beyond keyword indexing, typically supported by Natural Language Processing (NLP) and Information Extraction (IE) (Chinchor and Marsh 1998, Hovy, Hermjakob and Lin 2001, TARGETANCHOR).
4 Evaluation To evaluate our learning approach, we trained AQUAREA$ on the same development set of stories and tested it on the same test set of stories as those used in all past work on the reading comprehension task (Hirschman et al, 1999; Charniak et al, 2000; Riloffand Thelen, 2000; TARGETANCHOR).
There, a system that attempted a minimal understanding of both the question and the answer candidates, by translating them into their logical forms and using an inference engine, achieved a notably higher score than any surface-based system (Moldavan
