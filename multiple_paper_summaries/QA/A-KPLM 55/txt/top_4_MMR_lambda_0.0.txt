TARGETANCHOR focused on decomposition of a complex question into several sub-questions.
For example, TARGETANCHOR, Miller, Herschman, and Kelly (1978) on the LADDER system, and Biermann, Ballard, and Sigmon (1983) reported software failures at the rates of approximately 5, 2, and 2 percents, respectively.
The nugget-based paradigm has been previously detailed in a number of papers (TARGETANCHOR; Hildebrandt et al, 2004; Lin and Demner-Fushman, 2005a); here, we present only a short summary.
For instance, TARGETANCHOR report the following patterns for the relationships Inventor, Discoverer and Location: Relation Prec.
Moreover, the proof relies on lexico-semantic knowledge available from WordNet as well as rapidly formated knowledge bases generated by mechanisms described in TARGETANCHOR.
Current systems TARGETANCHOR already employ traditional information extraction and machine learning for extracting answers from relevant documents.
The words used in TARGETANCHOR are "happen", "take place" "this", "story".
Automatic pattern derivation is more appealing TARGETANCHOR.
Also, as pointed out by TARGETANCHOR, a score distribution heavily skewed towards zero makes meta-analysis of evaluation stability hard to perform.
Further improvements may be possible by using a sentence splitter instead of windows of fixed length, anaphora resolution, clustering of similar snippets to avoid ranking them separately, and identifying additional n-gram attributes by bootstrapping TARGETANCHOR.
Clarification dialogues can be applied to negotiate with users about the intent of their questions TARGETANCHOR.
Lexical synonymy (She esteemed him highly vs. She respected him greatly), syntactic variation (John paid the bill vs. The bill was paid by John), overlapping meanings (Anna turned at Elm vs. Anna rounded
