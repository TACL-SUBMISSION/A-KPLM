TARGETANCHOR focused on decomposition of a complex question into several sub-questions.
There are many previous work on paraphrase examples extraction or combining them with some applications such as information retrieval and question answering (Agichtein et al, 2001; Florence et al, 2003; TARGETANCHOR; Tomuro, 2003; Lin and Pantel, 2001;), information extraction (Shinyama et al, 2002; Shinyama and Sekine, 2003), machine translation (Hiroshi et al, 2003; Zhang and Yamamoto, 2003), multi-document (Barzilay et al, 2003).
TARGETANCHOR present an alternative ontology for type preference and describe a method for using this alternative ontology to extract particular answers using surface text patterns.
Quarc TARGETANCHOR utilizes manually generated rules that selects a sentence deemed to contain the answer based on a combination of syntactic similarity and semantic correspondence (i.e., semantic categories of nouns).
It may also partially reflect the intention of the current TREC QA Track that the question series introduced in TREC QA 2004 TARGETANCHOR simulate an interaction with a human, thus expected to arrive one at a time.
For example, TARGETANCHOR, Miller, Herschman, and Kelly (1978) on the LADDER system, and Biermann, Ballard, and Sigmon (1983) reported software failures at the rates of approximately 5, 2, and 2 percents, respectively.
Clarification dialogues can be applied to negotiate with users about the intent of their questions TARGETANCHOR.
Also, as pointed out by TARGETANCHOR, a score distribution heavily skewed towards zero makes meta-analysis of evaluation stability hard to perform.
Lexical synonymy (She esteemed him highly vs. She respected him greatly), syntactic variation (John paid the
