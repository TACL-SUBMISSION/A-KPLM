<html>
<head><title>sentence_pooling_strategy_top_2_adaptive_kplm_diversification_strategy_mmr_MMR_scoring_core_multinomial_cosine_MMR_alpha_0_dirichlet_prior_1_vectorisation_strategy_CountVectorizer_first_sent_selection_strategy_centroid_250_trimmed</title></head>
<body bgcolor="white">
<a name="1">[1]</a> <a href="#1" id=1>TARGETANCHOR focused on decomposition of a complex question into several sub-questions. </a>
<a name="2">[2]</a> <a href="#2" id=2>Lexical synonymy (She esteemed him highly vs. She respected him greatly), syntactic variation (John paid the bill vs. The bill was paid by John), overlapping meanings (Anna turned at Elm vs. Anna rounded the corner at Elm), and other phenomena interact to produce a broad range of choices for most language generation tasks (Hirst, 2003; TARGETANCHOR; Kozlowski et al, 2003). </a>
<a name="3">[3]</a> <a href="#3" id=3>We also compared our results across various interrogatives with those previously reported in TARGETANCHOR. </a>
<a name="4">[4]</a> <a href="#4" id=4>Automatic pattern derivation is more appealing TARGETANCHOR. </a>
<a name="5">[5]</a> <a href="#5" id=5>Further improvements may be possible by using a sentence splitter instead of windows of fixed length, anaphora resolution, clustering of similar snippets to avoid ranking them separately, and identifying additional n-gram attributes by bootstrapping TARGETANCHOR. </a>
<a name="6">[6]</a> <a href="#6" id=6>Clarification dialogues can be applied to negotiate with users about the intent of their questions TARGETANCHOR. </a>
<a name="7">[7]</a> <a href="#7" id=7>Current systems TARGETANCHOR already employ traditional information extraction and machine learning for extracting answers from relevant documents. </a>
<a name="8">[8]</a> <a href="#8" id=8>For example, TARGETANCHOR, Miller, Herschman, and Kelly (1978) on the LADDER system, and Biermann, Ballard, and Sigmon (1983) reported software failures at the rates of approximately 5, 2, and 2 percents, respectively. </a>
<a name="9">[9]</a> <a href="#9" id=9>The so-called "definition" or "other" questions at recent TREC evaluations TARGETANCHOR serve as good examples: "good answers" to these questions include interesting "nuggets" about a particular person, organization, entity, or event. </a>
<a name="10">[10]</a> <a href="#10" id=10>TARGETANCHOR summarizes experience with the Transformational Question Answering System (TQA) during the first full year of operation, 1978. </a>
<a name="11">[11]</a> <a href="#11" id=11>As such, all subsequent work (Charniak et al, 2000; </a>
</body>
</html>